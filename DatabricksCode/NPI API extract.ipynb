{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ffd67d-2859-4739-b2e5-63ab1f7fc22e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# No need to import or initialize SparkSession in Databricks notebooks\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# Use date.today() to get the current date in a format that Spark can handle\n",
    "current_date = date.today()\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"NPI Data\").getOrCreate()\n",
    "\n",
    "# Base URL for the NPI Registry API\n",
    "base_url = \"https://npiregistry.cms.hhs.gov/api/\"\n",
    "\n",
    "# Defining the parameters for the initial API request to get a list of NPIs\n",
    "params = {\n",
    "    \"version\": \"2.1\",  # API version\n",
    "    \"state\": \"CA\",  # Example state, replace with desired state or other criteria\n",
    "    \"city\": \"Los Angeles\",  # Example city, replace with desired city\n",
    "    \"limit\": 20,  # Limit the number of results for demonstration purposes\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0dab40-e121-4f42-8b29-db7256753412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Data Profile 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1741600127883,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "ansi",
         4494
        ],
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "7672a466-f772-4a7c-8091-2a65728ac2d8",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1741600108211,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1741600108132,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the initial API request to get a list of NPIs\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    npi_data = response.json()\n",
    "    npi_list = [result[\"number\"] for result in npi_data.get(\"results\", [])]\n",
    "\n",
    "    # Initialize a list to store detailed NPI information\n",
    "    detailed_results = []\n",
    "\n",
    "    # Loop through each NPI to get their details\n",
    "    for npi in npi_list:\n",
    "        detail_params = {\"version\": \"2.1\", \"number\": npi}\n",
    "        detail_response = requests.get(base_url, params=detail_params)\n",
    "\n",
    "        if detail_response.status_code == 200:\n",
    "            detail_data = detail_response.json()\n",
    "            if \"results\" in detail_data and detail_data[\"results\"]:\n",
    "                for result in detail_data[\"results\"]:\n",
    "                    npi_number = result.get(\"number\")\n",
    "                    basic_info = result.get(\"basic\", {})\n",
    "                    if result[\"enumeration_type\"] == \"NPI-1\":\n",
    "                        fname = basic_info.get(\"first_name\", \"\")\n",
    "                        lname = basic_info.get(\"last_name\", \"\")\n",
    "                    else:\n",
    "                        fname = basic_info.get(\"authorized_official_first_name\", \"\")\n",
    "                        lname = basic_info.get(\"authorized_official_last_name\", \"\")\n",
    "                    position = (\n",
    "                        basic_info.get(\"authorized_official_title_or_position\", \"\")\n",
    "                        if \"authorized_official_title_or_position\" in basic_info\n",
    "                        else \"\"\n",
    "                    )\n",
    "                    organisation = basic_info.get(\"organization_name\", \"\")\n",
    "                    last_updated = basic_info.get(\"last_updated\", \"\")\n",
    "                    detailed_results.append(\n",
    "                        {\n",
    "                            \"npi_id\": npi_number,\n",
    "                            \"first_name\": fname,\n",
    "                            \"last_name\": lname,\n",
    "                            \"position\": position,\n",
    "                            \"organisation_name\": organisation,\n",
    "                            \"last_updated\": last_updated,\n",
    "                            \"refreshed_at\": current_date,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    # Create a DataFrame\n",
    "    if detailed_results:\n",
    "        print(detailed_results)\n",
    "        df = spark.createDataFrame(detailed_results)\n",
    "        display(df)\n",
    "        df.write.format(\"parquet\").mode(\"overwrite\").save(\"/mnt/bronze/npi_extract/\")\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"npi_extract\")\n",
    "\n",
    "    else:\n",
    "        print(\"No detailed results found.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "458626a2-80ef-400a-b6de-a42cc98ac021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2263649506721872,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "NPI API extract",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
